---
layout: default
---

![](facereg.jpg)

# [](#header-1)Training face landmark detector

This application helps to train your own face landmark detector. You can train your own face landmark detection by just providing the paths for
directory containing the images and files containing their corresponding face landmarks. As this landmark detector was originally trained on
[HELEN dataset](http://www.ifp.illinois.edu/~vuongle2/helen/), the training follows the format of data provided in HELEN dataset.

The dataset consists of .txt files whose first line contains the image name which then follows the annotations.
The format of the file containing annotations should be of following format :
       
>       /directory/images/abc.jpg
>       123.45,345.65
>       321.67,543.89
>       .... , ....
>       .... , ....
       
The above format is similar to HELEN dataset which is used for training the model.

```js
// Command to be typed for running the sample
./sample_train_landmark_detector -annotations=/home/sukhad/Downloads/code/trainset/ -config=config.xml -face_cascade=lbpcascadefrontalface.xml -model=trained_model.dat -width=460 -height=460
```

## [](#header-2)Description of command parameters

> * **annotations** a : (REQUIRED) Path to annotations txt file [example - /data/annotations.txt]
> * **config** c : (REQUIRED) Path to configuration xml file containing parameters for training.[ example - /data/config.xml]
> * **model** m :  (REQUIRED) Path to configuration xml file containing parameters for training.[ example - /data/model.dat]
> * **width** w : (OPTIONAL)  The width which you want all images to get to scale the annotations. Large images are slow to process [default = 460]
> * **height** h : (OPTIONAL) The height which you want all images to get to scale the annotations. Large images are slow to process [default = 460]
> * **face_cascade** f (REQUIRED) Path to the face cascade xml file which you want to use as a detector.

### [](#header-2)Description of training parameters

The configuration file described above which is used while training contains the training parameters which are required for training.

**The description of parameters is as follows :**

> * **Cascade depth :** This stores the depth of cascade of regressors used for training.
> * **Tree depth :** This stores the depth of trees created as weak learners during gradient boosting.
> * **Number of trees per cascade level :** This stores number of trees required per cascade level.
> * **Learning rate :** This stores the learning rate for gradient boosting.This is required to prevent overfitting using shrinkage.
> * **Oversampling amount :** This stores the oversampling amount for the samples.
> * **Number of test coordinates :** This stores number of test coordinates to be generated as samples to decide for making the split.
> * **Lambda** This stores the value used for calculating the probabilty which helps to select closer pixels for making the split.
> * **Number of test splits :** This stores the number of test splits to be generated before making the best split.

To get more detailed description about the training parameters you can refer to the [Research paper](https://pdfs.semanticscholar.org/d78b/6a5b0dcaa81b1faea5fb0000045a62513567.pdf).

### [](#header-2)Understanding code

For understanding the code jump to this [page](another.md)

### [](#header-2)Error rate

**The error rate on trained images depends on the number of images used for training used as follows :**

![](train.png)

**The error rate on test images depends on the number of images used for training used as follows :**

![](test.png)

